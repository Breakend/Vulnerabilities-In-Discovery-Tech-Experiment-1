Cache flushing functions are in the middle of completely<br>
unrelated stuff in mm/mem.c<br>
<br>
Create a dedicated mm/cacheflush.c for those functions.<br>
<br>
Also cleanup the list of included headers.<br>
<br>
Signed-off-by: Christophe Leroy <christophe.leroy@xxxxxxxxxx><br>
---<br>
 arch/powerpc/mm/Makefile     |   3 +-<br>
 arch/powerpc/mm/cacheflush.c | 255 +++++++++++++++++++++++++++++++<br>
 arch/powerpc/mm/mem.c        | 281 -----------------------------------<br>
 3 files changed, 257 insertions(+), 282 deletions(-)<br>
 create mode 100644 arch/powerpc/mm/cacheflush.c<br>
<br>
diff --git a/arch/powerpc/mm/Makefile b/arch/powerpc/mm/Makefile<br>
index 3b4e9e4e25ea..c3df3a8501d4 100644<br>
--- a/arch/powerpc/mm/Makefile<br>
+++ b/arch/powerpc/mm/Makefile<br>
@@ -8,7 +8,8 @@ ccflags-$(CONFIG_PPC64)	:= $(NO_MINIMAL_TOC)<br>
 obj-y				:= fault.o mem.o pgtable.o mmap.o maccess.o \<br>
 				   init_$(BITS).o pgtable_$(BITS).o \<br>
 				   pgtable-frag.o ioremap.o ioremap_$(BITS).o \<br>
-				   init-common.o mmu_context.o drmem.o<br>
+				   init-common.o mmu_context.o drmem.o \<br>
+				   cacheflush.o<br>
 obj-$(CONFIG_PPC_MMU_NOHASH)	+= nohash/<br>
 obj-$(CONFIG_PPC_BOOK3S_32)	+= book3s32/<br>
 obj-$(CONFIG_PPC_BOOK3S_64)	+= book3s64/<br>
diff --git a/arch/powerpc/mm/cacheflush.c b/arch/powerpc/mm/cacheflush.c<br>
new file mode 100644<br>
index 000000000000..40613d2fda37<br>
--- /dev/null<br>
+++ b/arch/powerpc/mm/cacheflush.c<br>
@@ -0,0 +1,255 @@<br>
+// SPDX-License-Identifier: GPL-2.0-or-later<br>
+<br>
+#include <linux/highmem.h><br>
+#include <linux/kprobes.h><br>
+<br>
+/**<br>
+ * flush_coherent_icache() - if a CPU has a coherent icache, flush it<br>
+ * @addr: The base address to use (can be any valid address, the whole cache will be flushed)<br>
+ * Return true if the cache was flushed, false otherwise<br>
+ */<br>
+static inline bool flush_coherent_icache(unsigned long addr)<br>
+{<br>
+	/*<br>
+	 * For a snooping icache, we still need a dummy icbi to purge all the<br>
+	 * prefetched instructions from the ifetch buffers. We also need a sync<br>
+	 * before the icbi to order the the actual stores to memory that might<br>
+	 * have modified instructions with the icbi.<br>
+	 */<br>
+	if (cpu_has_feature(CPU_FTR_COHERENT_ICACHE)) {<br>
+		mb(); /* sync */<br>
+		allow_read_from_user((const void __user *)addr, L1_CACHE_BYTES);<br>
+		icbi((void *)addr);<br>
+		prevent_read_from_user((const void __user *)addr, L1_CACHE_BYTES);<br>
+		mb(); /* sync */<br>
+		isync();<br>
+		return true;<br>
+	}<br>
+<br>
+	return false;<br>
+}<br>
+<br>
+/**<br>
+ * invalidate_icache_range() - Flush the icache by issuing icbi across an address range<br>
+ * @start: the start address<br>
+ * @stop: the stop address (exclusive)<br>
+ */<br>
+static void invalidate_icache_range(unsigned long start, unsigned long stop)<br>
+{<br>
+	unsigned long shift = l1_icache_shift();<br>
+	unsigned long bytes = l1_icache_bytes();<br>
+	char *addr = (char *)(start & ~(bytes - 1));<br>
+	unsigned long size = stop - (unsigned long)addr + (bytes - 1);<br>
+	unsigned long i;<br>
+<br>
+	for (i = 0; i < size >> shift; i++, addr += bytes)<br>
+		icbi(addr);<br>
+<br>
+	mb(); /* sync */<br>
+	isync();<br>
+}<br>
+<br>
+/**<br>
+ * flush_icache_range: Write any modified data cache blocks out to memory<br>
+ * and invalidate the corresponding blocks in the instruction cache<br>
+ *<br>
+ * Generic code will call this after writing memory, before executing from it.<br>
+ *<br>
+ * @start: the start address<br>
+ * @stop: the stop address (exclusive)<br>
+ */<br>
+void flush_icache_range(unsigned long start, unsigned long stop)<br>
+{<br>
+	if (flush_coherent_icache(start))<br>
+		return;<br>
+<br>
+	clean_dcache_range(start, stop);<br>
+<br>
+	if (IS_ENABLED(CONFIG_44x)) {<br>
+		/*<br>
+		 * Flash invalidate on 44x because we are passed kmapped<br>
+		 * addresses and this doesn't work for userspace pages due to<br>
+		 * the virtually tagged icache.<br>
+		 */<br>
+		iccci((void *)start);<br>
+		mb(); /* sync */<br>
+		isync();<br>
+	} else<br>
+		invalidate_icache_range(start, stop);<br>
+}<br>
+EXPORT_SYMBOL(flush_icache_range);<br>
+<br>
+#if !defined(CONFIG_PPC_8xx) && !defined(CONFIG_PPC64)<br>
+/**<br>
+ * flush_dcache_icache_phys() - Flush a page by it's physical address<br>
+ * @physaddr: the physical address of the page<br>
+ */<br>
+static void flush_dcache_icache_phys(unsigned long physaddr)<br>
+{<br>
+	unsigned long bytes = l1_dcache_bytes();<br>
+	unsigned long nb = PAGE_SIZE / bytes;<br>
+	unsigned long addr = physaddr & PAGE_MASK;<br>
+	unsigned long msr, msr0;<br>
+	unsigned long loop1 = addr, loop2 = addr;<br>
+<br>
+	msr0 = mfmsr();<br>
+	msr = msr0 & ~MSR_DR;<br>
+	/*<br>
+	 * This must remain as ASM to prevent potential memory accesses<br>
+	 * while the data MMU is disabled<br>
+	 */<br>
+	asm volatile(<br>
+		"   mtctr %2;\n"<br>
+		"   mtmsr %3;\n"<br>
+		"   isync;\n"<br>
+		"0: dcbst   0, %0;\n"<br>
+		"   addi    %0, %0, %4;\n"<br>
+		"   bdnz    0b;\n"<br>
+		"   sync;\n"<br>
+		"   mtctr %2;\n"<br>
+		"1: icbi    0, %1;\n"<br>
+		"   addi    %1, %1, %4;\n"<br>
+		"   bdnz    1b;\n"<br>
+		"   sync;\n"<br>
+		"   mtmsr %5;\n"<br>
+		"   isync;\n"<br>
+		: "+&r" (loop1), "+&r" (loop2)<br>
+		: "r" (nb), "r" (msr), "i" (bytes), "r" (msr0)<br>
+		: "ctr", "memory");<br>
+}<br>
+NOKPROBE_SYMBOL(flush_dcache_icache_phys)<br>
+#endif // !defined(CONFIG_PPC_8xx) && !defined(CONFIG_PPC64)<br>
+<br>
+/*<br>
+ * This is called when a page has been modified by the kernel.<br>
+ * It just marks the page as not i-cache clean.  We do the i-cache<br>
+ * flush later when the page is given to a user process, if necessary.<br>
+ */<br>
+void flush_dcache_page(struct page *page)<br>
+{<br>
+	if (cpu_has_feature(CPU_FTR_COHERENT_ICACHE))<br>
+		return;<br>
+	/* avoid an atomic op if possible */<br>
+	if (test_bit(PG_dcache_clean, &page->flags))<br>
+		clear_bit(PG_dcache_clean, &page->flags);<br>
+}<br>
+EXPORT_SYMBOL(flush_dcache_page);<br>
+<br>
+static void flush_dcache_icache_hugepage(struct page *page)<br>
+{<br>
+	int i;<br>
+	void *start;<br>
+<br>
+	BUG_ON(!PageCompound(page));<br>
+<br>
+	for (i = 0; i < compound_nr(page); i++) {<br>
+		if (!PageHighMem(page)) {<br>
+			__flush_dcache_icache(page_address(page+i));<br>
+		} else {<br>
+			start = kmap_atomic(page+i);<br>
+			__flush_dcache_icache(start);<br>
+			kunmap_atomic(start);<br>
+		}<br>
+	}<br>
+}<br>
+<br>
+void flush_dcache_icache_page(struct page *page)<br>
+{<br>
+<br>
+	if (PageCompound(page))<br>
+		return flush_dcache_icache_hugepage(page);<br>
+<br>
+#if defined(CONFIG_PPC_8xx) || defined(CONFIG_PPC64)<br>
+	/* On 8xx there is no need to kmap since highmem is not supported */<br>
+	__flush_dcache_icache(page_address(page));<br>
+#else<br>
+	if (IS_ENABLED(CONFIG_BOOKE) || sizeof(phys_addr_t) > sizeof(void *)) {<br>
+		void *start = kmap_atomic(page);<br>
+		__flush_dcache_icache(start);<br>
+		kunmap_atomic(start);<br>
+	} else {<br>
+		unsigned long addr = page_to_pfn(page) << PAGE_SHIFT;<br>
+<br>
+		if (flush_coherent_icache(addr))<br>
+			return;<br>
+		flush_dcache_icache_phys(addr);<br>
+	}<br>
+#endif<br>
+}<br>
+EXPORT_SYMBOL(flush_dcache_icache_page);<br>
+<br>
+/**<br>
+ * __flush_dcache_icache(): Flush a particular page from the data cache to RAM.<br>
+ * Note: this is necessary because the instruction cache does *not*<br>
+ * snoop from the data cache.<br>
+ *<br>
+ * @page: the address of the page to flush<br>
+ */<br>
+void __flush_dcache_icache(void *p)<br>
+{<br>
+	unsigned long addr = (unsigned long)p;<br>
+<br>
+	if (flush_coherent_icache(addr))<br>
+		return;<br>
+<br>
+	clean_dcache_range(addr, addr + PAGE_SIZE);<br>
+<br>
+	/*<br>
+	 * We don't flush the icache on 44x. Those have a virtual icache and we<br>
+	 * don't have access to the virtual address here (it's not the page<br>
+	 * vaddr but where it's mapped in user space). The flushing of the<br>
+	 * icache on these is handled elsewhere, when a change in the address<br>
+	 * space occurs, before returning to user space.<br>
+	 */<br>
+<br>
+	if (mmu_has_feature(MMU_FTR_TYPE_44x))<br>
+		return;<br>
+<br>
+	invalidate_icache_range(addr, addr + PAGE_SIZE);<br>
+}<br>
+<br>
+void clear_user_page(void *page, unsigned long vaddr, struct page *pg)<br>
+{<br>
+	clear_page(page);<br>
+<br>
+	/*<br>
+	 * We shouldn't have to do this, but some versions of glibc<br>
+	 * require it (ld.so assumes zero filled pages are icache clean)<br>
+	 * - Anton<br>
+	 */<br>
+	flush_dcache_page(pg);<br>
+}<br>
+EXPORT_SYMBOL(clear_user_page);<br>
+<br>
+void copy_user_page(void *vto, void *vfrom, unsigned long vaddr,<br>
+		    struct page *pg)<br>
+{<br>
+	copy_page(vto, vfrom);<br>
+<br>
+	/*<br>
+	 * We should be able to use the following optimisation, however<br>
+	 * there are two problems.<br>
+	 * Firstly a bug in some versions of binutils meant PLT sections<br>
+	 * were not marked executable.<br>
+	 * Secondly the first word in the GOT section is blrl, used<br>
+	 * to establish the GOT address. Until recently the GOT was<br>
+	 * not marked executable.<br>
+	 * - Anton<br>
+	 */<br>
+#if 0<br>
+	if (!vma->vm_file && ((vma->vm_flags & VM_EXEC) == 0))<br>
+		return;<br>
+#endif<br>
+<br>
+	flush_dcache_page(pg);<br>
+}<br>
+<br>
+void flush_icache_user_page(struct vm_area_struct *vma, struct page *page,<br>
+			     unsigned long addr, int len)<br>
+{<br>
+	unsigned long maddr;<br>
+<br>
+	maddr = (unsigned long) kmap(page) + (addr & ~PAGE_MASK);<br>
+	flush_icache_range(maddr, maddr + len);<br>
+	kunmap(page);<br>
+}<br>
diff --git a/arch/powerpc/mm/mem.c b/arch/powerpc/mm/mem.c<br>
index 7a59a5c9aa5d..6564b4d81324 100644<br>
--- a/arch/powerpc/mm/mem.c<br>
+++ b/arch/powerpc/mm/mem.c<br>
@@ -12,45 +12,15 @@<br>
  *    Copyright (C) 1991, 1992, 1993, 1994  Linus Torvalds<br>
  */<br>
 <br>
-#include <linux/export.h><br>
-#include <linux/sched.h><br>
-#include <linux/kernel.h><br>
-#include <linux/errno.h><br>
-#include <linux/string.h><br>
-#include <linux/gfp.h><br>
-#include <linux/types.h><br>
-#include <linux/mm.h><br>
-#include <linux/stddef.h><br>
-#include <linux/init.h><br>
 #include <linux/memblock.h><br>
 #include <linux/highmem.h><br>
-#include <linux/initrd.h><br>
-#include <linux/pagemap.h><br>
 #include <linux/suspend.h><br>
-#include <linux/hugetlb.h><br>
-#include <linux/slab.h><br>
-#include <linux/vmalloc.h><br>
-#include <linux/memremap.h><br>
 #include <linux/dma-direct.h><br>
-#include <linux/kprobes.h><br>
 <br>
-#include <asm/prom.h><br>
-#include <asm/io.h><br>
-#include <asm/mmu_context.h><br>
-#include <asm/mmu.h><br>
-#include <asm/smp.h><br>
 #include <asm/machdep.h><br>
-#include <asm/btext.h><br>
-#include <asm/tlb.h><br>
-#include <asm/sections.h><br>
-#include <asm/sparsemem.h><br>
-#include <asm/vdso.h><br>
-#include <asm/fixmap.h><br>
-#include <asm/swiotlb.h><br>
 #include <asm/rtas.h><br>
 #include <asm/kasan.h><br>
 #include <asm/svm.h><br>
-#include <asm/mmzone.h><br>
 <br>
 #include <mm/mmu_decl.h><br>
 <br>
@@ -340,257 +310,6 @@ void free_initmem(void)<br>
 	free_initmem_default(POISON_FREE_INITMEM);<br>
 }<br>
 <br>
-/**<br>
- * flush_coherent_icache() - if a CPU has a coherent icache, flush it<br>
- * @addr: The base address to use (can be any valid address, the whole cache will be flushed)<br>
- * Return true if the cache was flushed, false otherwise<br>
- */<br>
-static inline bool flush_coherent_icache(unsigned long addr)<br>
-{<br>
-	/*<br>
-	 * For a snooping icache, we still need a dummy icbi to purge all the<br>
-	 * prefetched instructions from the ifetch buffers. We also need a sync<br>
-	 * before the icbi to order the the actual stores to memory that might<br>
-	 * have modified instructions with the icbi.<br>
-	 */<br>
-	if (cpu_has_feature(CPU_FTR_COHERENT_ICACHE)) {<br>
-		mb(); /* sync */<br>
-		allow_read_from_user((const void __user *)addr, L1_CACHE_BYTES);<br>
-		icbi((void *)addr);<br>
-		prevent_read_from_user((const void __user *)addr, L1_CACHE_BYTES);<br>
-		mb(); /* sync */<br>
-		isync();<br>
-		return true;<br>
-	}<br>
-<br>
-	return false;<br>
-}<br>
-<br>
-/**<br>
- * invalidate_icache_range() - Flush the icache by issuing icbi across an address range<br>
- * @start: the start address<br>
- * @stop: the stop address (exclusive)<br>
- */<br>
-static void invalidate_icache_range(unsigned long start, unsigned long stop)<br>
-{<br>
-	unsigned long shift = l1_icache_shift();<br>
-	unsigned long bytes = l1_icache_bytes();<br>
-	char *addr = (char *)(start & ~(bytes - 1));<br>
-	unsigned long size = stop - (unsigned long)addr + (bytes - 1);<br>
-	unsigned long i;<br>
-<br>
-	for (i = 0; i < size >> shift; i++, addr += bytes)<br>
-		icbi(addr);<br>
-<br>
-	mb(); /* sync */<br>
-	isync();<br>
-}<br>
-<br>
-/**<br>
- * flush_icache_range: Write any modified data cache blocks out to memory<br>
- * and invalidate the corresponding blocks in the instruction cache<br>
- *<br>
- * Generic code will call this after writing memory, before executing from it.<br>
- *<br>
- * @start: the start address<br>
- * @stop: the stop address (exclusive)<br>
- */<br>
-void flush_icache_range(unsigned long start, unsigned long stop)<br>
-{<br>
-	if (flush_coherent_icache(start))<br>
-		return;<br>
-<br>
-	clean_dcache_range(start, stop);<br>
-<br>
-	if (IS_ENABLED(CONFIG_44x)) {<br>
-		/*<br>
-		 * Flash invalidate on 44x because we are passed kmapped<br>
-		 * addresses and this doesn't work for userspace pages due to<br>
-		 * the virtually tagged icache.<br>
-		 */<br>
-		iccci((void *)start);<br>
-		mb(); /* sync */<br>
-		isync();<br>
-	} else<br>
-		invalidate_icache_range(start, stop);<br>
-}<br>
-EXPORT_SYMBOL(flush_icache_range);<br>
-<br>
-#if !defined(CONFIG_PPC_8xx) && !defined(CONFIG_PPC64)<br>
-/**<br>
- * flush_dcache_icache_phys() - Flush a page by it's physical address<br>
- * @physaddr: the physical address of the page<br>
- */<br>
-static void flush_dcache_icache_phys(unsigned long physaddr)<br>
-{<br>
-	unsigned long bytes = l1_dcache_bytes();<br>
-	unsigned long nb = PAGE_SIZE / bytes;<br>
-	unsigned long addr = physaddr & PAGE_MASK;<br>
-	unsigned long msr, msr0;<br>
-	unsigned long loop1 = addr, loop2 = addr;<br>
-<br>
-	msr0 = mfmsr();<br>
-	msr = msr0 & ~MSR_DR;<br>
-	/*<br>
-	 * This must remain as ASM to prevent potential memory accesses<br>
-	 * while the data MMU is disabled<br>
-	 */<br>
-	asm volatile(<br>
-		"   mtctr %2;\n"<br>
-		"   mtmsr %3;\n"<br>
-		"   isync;\n"<br>
-		"0: dcbst   0, %0;\n"<br>
-		"   addi    %0, %0, %4;\n"<br>
-		"   bdnz    0b;\n"<br>
-		"   sync;\n"<br>
-		"   mtctr %2;\n"<br>
-		"1: icbi    0, %1;\n"<br>
-		"   addi    %1, %1, %4;\n"<br>
-		"   bdnz    1b;\n"<br>
-		"   sync;\n"<br>
-		"   mtmsr %5;\n"<br>
-		"   isync;\n"<br>
-		: "+&r" (loop1), "+&r" (loop2)<br>
-		: "r" (nb), "r" (msr), "i" (bytes), "r" (msr0)<br>
-		: "ctr", "memory");<br>
-}<br>
-NOKPROBE_SYMBOL(flush_dcache_icache_phys)<br>
-#endif // !defined(CONFIG_PPC_8xx) && !defined(CONFIG_PPC64)<br>
-<br>
-/*<br>
- * This is called when a page has been modified by the kernel.<br>
- * It just marks the page as not i-cache clean.  We do the i-cache<br>
- * flush later when the page is given to a user process, if necessary.<br>
- */<br>
-void flush_dcache_page(struct page *page)<br>
-{<br>
-	if (cpu_has_feature(CPU_FTR_COHERENT_ICACHE))<br>
-		return;<br>
-	/* avoid an atomic op if possible */<br>
-	if (test_bit(PG_dcache_clean, &page->flags))<br>
-		clear_bit(PG_dcache_clean, &page->flags);<br>
-}<br>
-EXPORT_SYMBOL(flush_dcache_page);<br>
-<br>
-static void flush_dcache_icache_hugepage(struct page *page)<br>
-{<br>
-	int i;<br>
-	void *start;<br>
-<br>
-	BUG_ON(!PageCompound(page));<br>
-<br>
-	for (i = 0; i < compound_nr(page); i++) {<br>
-		if (!PageHighMem(page)) {<br>
-			__flush_dcache_icache(page_address(page+i));<br>
-		} else {<br>
-			start = kmap_atomic(page+i);<br>
-			__flush_dcache_icache(start);<br>
-			kunmap_atomic(start);<br>
-		}<br>
-	}<br>
-}<br>
-<br>
-void flush_dcache_icache_page(struct page *page)<br>
-{<br>
-<br>
-	if (PageCompound(page))<br>
-		return flush_dcache_icache_hugepage(page);<br>
-<br>
-#if defined(CONFIG_PPC_8xx) || defined(CONFIG_PPC64)<br>
-	/* On 8xx there is no need to kmap since highmem is not supported */<br>
-	__flush_dcache_icache(page_address(page));<br>
-#else<br>
-	if (IS_ENABLED(CONFIG_BOOKE) || sizeof(phys_addr_t) > sizeof(void *)) {<br>
-		void *start = kmap_atomic(page);<br>
-		__flush_dcache_icache(start);<br>
-		kunmap_atomic(start);<br>
-	} else {<br>
-		unsigned long addr = page_to_pfn(page) << PAGE_SHIFT;<br>
-<br>
-		if (flush_coherent_icache(addr))<br>
-			return;<br>
-		flush_dcache_icache_phys(addr);<br>
-	}<br>
-#endif<br>
-}<br>
-EXPORT_SYMBOL(flush_dcache_icache_page);<br>
-<br>
-/**<br>
- * __flush_dcache_icache(): Flush a particular page from the data cache to RAM.<br>
- * Note: this is necessary because the instruction cache does *not*<br>
- * snoop from the data cache.<br>
- *<br>
- * @page: the address of the page to flush<br>
- */<br>
-void __flush_dcache_icache(void *p)<br>
-{<br>
-	unsigned long addr = (unsigned long)p;<br>
-<br>
-	if (flush_coherent_icache(addr))<br>
-		return;<br>
-<br>
-	clean_dcache_range(addr, addr + PAGE_SIZE);<br>
-<br>
-	/*<br>
-	 * We don't flush the icache on 44x. Those have a virtual icache and we<br>
-	 * don't have access to the virtual address here (it's not the page<br>
-	 * vaddr but where it's mapped in user space). The flushing of the<br>
-	 * icache on these is handled elsewhere, when a change in the address<br>
-	 * space occurs, before returning to user space.<br>
-	 */<br>
-<br>
-	if (mmu_has_feature(MMU_FTR_TYPE_44x))<br>
-		return;<br>
-<br>
-	invalidate_icache_range(addr, addr + PAGE_SIZE);<br>
-}<br>
-<br>
-void clear_user_page(void *page, unsigned long vaddr, struct page *pg)<br>
-{<br>
-	clear_page(page);<br>
-<br>
-	/*<br>
-	 * We shouldn't have to do this, but some versions of glibc<br>
-	 * require it (ld.so assumes zero filled pages are icache clean)<br>
-	 * - Anton<br>
-	 */<br>
-	flush_dcache_page(pg);<br>
-}<br>
-EXPORT_SYMBOL(clear_user_page);<br>
-<br>
-void copy_user_page(void *vto, void *vfrom, unsigned long vaddr,<br>
-		    struct page *pg)<br>
-{<br>
-	copy_page(vto, vfrom);<br>
-<br>
-	/*<br>
-	 * We should be able to use the following optimisation, however<br>
-	 * there are two problems.<br>
-	 * Firstly a bug in some versions of binutils meant PLT sections<br>
-	 * were not marked executable.<br>
-	 * Secondly the first word in the GOT section is blrl, used<br>
-	 * to establish the GOT address. Until recently the GOT was<br>
-	 * not marked executable.<br>
-	 * - Anton<br>
-	 */<br>
-#if 0<br>
-	if (!vma->vm_file && ((vma->vm_flags & VM_EXEC) == 0))<br>
-		return;<br>
-#endif<br>
-<br>
-	flush_dcache_page(pg);<br>
-}<br>
-<br>
-void flush_icache_user_page(struct vm_area_struct *vma, struct page *page,<br>
-			     unsigned long addr, int len)<br>
-{<br>
-	unsigned long maddr;<br>
-<br>
-	maddr = (unsigned long) kmap(page) + (addr & ~PAGE_MASK);<br>
-	flush_icache_range(maddr, maddr + len);<br>
-	kunmap(page);<br>
-}<br>
-<br>
 /*<br>
  * System memory should not be in /proc/iomem but various tools expect it<br>
  * (eg kdump).<br>
-- <br>
2.25.0<br>
<br>
<br>

