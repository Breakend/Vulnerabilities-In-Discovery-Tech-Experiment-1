On Thu, Apr 8, 2021 at 6:08 AM Mark Rutland <mark.rutland@xxxxxxx> wrote:<br>
><i></i><br>
><i> On Wed, Apr 07, 2021 at 01:44:37PM +0100, Will Deacon wrote:</i><br>
><i> > [Moving Mark to To: since I'd like his view on this]</i><br>
><i> ></i><br>
><i> > On Thu, Apr 01, 2021 at 02:45:21PM -0500, Rob Herring wrote:</i><br>
><i> > > On Wed, Mar 31, 2021 at 11:01 AM Will Deacon <will@xxxxxxxxxx> wrote:</i><br>
><i> > > ></i><br>
><i> > > > On Tue, Mar 30, 2021 at 12:09:38PM -0500, Rob Herring wrote:</i><br>
><i> > > > > On Tue, Mar 30, 2021 at 10:31 AM Will Deacon <will@xxxxxxxxxx> wrote:</i><br>
><i> > > > > ></i><br>
><i> > > > > > On Wed, Mar 10, 2021 at 05:08:29PM -0700, Rob Herring wrote:</i><br>
><i> > > > > > > From: Raphael Gault <raphael.gault@xxxxxxx></i><br>
><i></i><br>
><i> > > > > > > +static void armv8pmu_event_unmapped(struct perf_event *event, struct mm_struct *mm)</i><br>
><i> > > > > > > +{</i><br>
><i> > > > > > > +     struct arm_pmu *armpmu = to_arm_pmu(event->pmu);</i><br>
><i> > > > > > > +</i><br>
><i> > > > > > > +     if (!(event->hw.flags & ARMPMU_EL0_RD_CNTR))</i><br>
><i> > > > > > > +             return;</i><br>
><i> > > > > > > +</i><br>
><i> > > > > > > +     if (atomic_dec_and_test(&mm->context.pmu_direct_access))</i><br>
><i> > > > > > > +             on_each_cpu_mask(&armpmu->supported_cpus, refresh_pmuserenr, mm, 1);</i><br>
><i> > > > > ></i><br>
><i> > > > > > Given that the pmu_direct_access field is global per-mm, won't this go</i><br>
><i> > > > > > wrong if multiple PMUs are opened by the same process but only a subset</i><br>
><i> > > > > > are exposed to EL0? Perhaps pmu_direct_access should be treated as a mask</i><br>
><i> > > > > > rather than a counter, so that we can 'and' it with the supported_cpus for</i><br>
><i> > > > > > the PMU we're dealing with.</i><br>
><i> > > > ></i><br>
><i> > > > > It needs to be a count to support multiple events on the same PMU. If</i><br>
><i> > > > > the event is not enabled for EL0, then we'd exit out on the</i><br>
><i> > > > > ARMPMU_EL0_RD_CNTR check. So I think we're fine.</i><br>
><i> > > ></i><br>
><i> > > > I'm still not convinced; pmu_direct_access is shared between PMUs, so</i><br>
><i> > > > testing the result of atomic_dec_and_test() just doesn't make sense to</i><br>
><i> > > > me, as another PMU could be playing with the count.</i><br>
><i> > ></i><br>
><i> > > How is that a problem? Let's make a concrete example:</i><br>
><i> > ></i><br>
><i> > > map PMU1:event2 -> pmu_direct_access = 1 -> enable access</i><br>
><i> > > map PMU2:event3 -> pmu_direct_access = 2</i><br>
><i> > > map PMU1:event4 -> pmu_direct_access = 3</i><br>
><i> > > unmap PMU2:event3 -> pmu_direct_access = 2</i><br>
><i> > > unmap PMU1:event2 -> pmu_direct_access = 1</i><br>
><i> > > unmap PMU1:event4 -> pmu_direct_access = 0 -> disable access</i><br>
><i> > ></i><br>
><i> > > The only issue I can see is PMU2 remains enabled for user access until</i><br>
><i> > > the last unmap. But we're sharing the mm, so who cares? Also, in this</i><br>
><i> > > scenario it is the user's problem to pin themselves to cores sharing a</i><br>
><i> > > PMU. If the user doesn't do that, they get to keep the pieces.</i><br>
><i> ></i><br>
><i> > I guess I'm just worried about exposing the counters to userspace after</i><br>
><i> > the PMU driver (or perf core?) thinks that they're no longer exposed in</i><br>
><i> > case we leak other events.</i><br>
><i></i><br>
><i> IMO that's not practically different from the single-PMU case (i.e.</i><br>
><i> multi-PMU isn't material, either we have a concern with leaking or we</i><br>
><i> don't); more on that below.</i><br>
><i></i><br>
><i> While it looks odd to place this on the mm, I don't think it's the end</i><br>
><i> of the world.</i><br>
><i></i><br>
><i> > However, I'm not sure how this is supposed to work normally: what</i><br>
><i> > happens if e.g. a privileged user has a per-cpu counter for a kernel</i><br>
><i> > event while a task has a counter with direct access -- can that task</i><br>
><i> > read the kernel event out of the PMU registers from userspace?</i><br>
><i></i><br>
><i> Yes -- userspace could go read any counters even though it isn't</i><br>
><i> supposed to, and could potentially infer information from those. It</i><br>
><i> won't have access to the config registers or kernel data structures, so</i><br>
><i> it isn't guaranteed to know what the even is or when it is</i><br>
><i> context-switched/reprogrammed/etc.</i><br>
><i></i><br>
><i> If we believe that's a problem, then it's difficult to do anything</i><br>
><i> robust other than denying userspace access entirely, since disabling</i><br>
><i> userspace access while in use would surprise applications, and denying</i><br>
><i> privileged events would need some global state that we consult at event</i><br>
><i> creation time (in addition to being an inversion of privilege).</i><br>
><i></i><br>
><i> IIRC there was some fuss about this a while back on x86; I'll go dig and</i><br>
><i> see what I can find, unless Peter has a memory...</i><br>
<br>
Maybe this one[1].<br>
<br>
Rob<br>
<br>
[1] <a  rel="nofollow" href="https://lore.kernel.org/lkml/20200730123815.18518-1-kan.liang@xxxxxxxxxxxxxxx/">https://lore.kernel.org/lkml/20200730123815.18518-1-kan.liang@xxxxxxxxxxxxxxx/</a><br>
<br>
<br>

