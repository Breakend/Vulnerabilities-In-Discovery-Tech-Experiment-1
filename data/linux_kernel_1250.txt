<br>
<br>
On 4/7/21 10:56 PM, Mike Rapoport wrote:<br>
><i> From: Mike Rapoport <rppt@xxxxxxxxxxxxx></i><br>
><i> </i><br>
><i> The struct pages representing a reserved memory region are initialized</i><br>
><i> using reserve_bootmem_range() function. This function is called for each</i><br>
><i> reserved region just before the memory is freed from memblock to the buddy</i><br>
><i> page allocator.</i><br>
><i> </i><br>
><i> The struct pages for MEMBLOCK_NOMAP regions are kept with the default</i><br>
><i> values set by the memory map initialization which makes it necessary to</i><br>
><i> have a special treatment for such pages in pfn_valid() and</i><br>
><i> pfn_valid_within().</i><br>
><i> </i><br>
><i> Split out initialization of the reserved pages to a function with a</i><br>
><i> meaningful name and treat the MEMBLOCK_NOMAP regions the same way as the</i><br>
><i> reserved regions and mark struct pages for the NOMAP regions as</i><br>
><i> PageReserved.</i><br>
<br>
This would definitely need updating the comment for MEMBLOCK_NOMAP definition<br>
in include/linux/memblock.h just to make the semantics is clear, though arm64<br>
is currently the only user for MEMBLOCK_NOMAP.<br>
<br>
><i> </i><br>
><i> Signed-off-by: Mike Rapoport <rppt@xxxxxxxxxxxxx></i><br>
><i> ---</i><br>
><i>  mm/memblock.c | 23 +++++++++++++++++++++--</i><br>
><i>  1 file changed, 21 insertions(+), 2 deletions(-)</i><br>
><i> </i><br>
><i> diff --git a/mm/memblock.c b/mm/memblock.c</i><br>
><i> index afaefa8fc6ab..6b7ea9d86310 100644</i><br>
><i> --- a/mm/memblock.c</i><br>
><i> +++ b/mm/memblock.c</i><br>
><i> @@ -2002,6 +2002,26 @@ static unsigned long __init __free_memory_core(phys_addr_t start,</i><br>
><i>  	return end_pfn - start_pfn;</i><br>
><i>  }</i><br>
><i>  </i><br>
><i> +static void __init memmap_init_reserved_pages(void)</i><br>
><i> +{</i><br>
><i> +	struct memblock_region *region;</i><br>
><i> +	phys_addr_t start, end;</i><br>
><i> +	u64 i;</i><br>
><i> +</i><br>
><i> +	/* initialize struct pages for the reserved regions */</i><br>
><i> +	for_each_reserved_mem_range(i, &start, &end)</i><br>
><i> +		reserve_bootmem_region(start, end);</i><br>
><i> +</i><br>
><i> +	/* and also treat struct pages for the NOMAP regions as PageReserved */</i><br>
><i> +	for_each_mem_region(region) {</i><br>
><i> +		if (memblock_is_nomap(region)) {</i><br>
><i> +			start = region->base;</i><br>
><i> +			end = start + region->size;</i><br>
><i> +			reserve_bootmem_region(start, end);</i><br>
><i> +		}</i><br>
><i> +	}</i><br>
><i> +}</i><br>
><i> +</i><br>
><i>  static unsigned long __init free_low_memory_core_early(void)</i><br>
><i>  {</i><br>
><i>  	unsigned long count = 0;</i><br>
><i> @@ -2010,8 +2030,7 @@ static unsigned long __init free_low_memory_core_early(void)</i><br>
><i>  </i><br>
><i>  	memblock_clear_hotplug(0, -1);</i><br>
><i>  </i><br>
><i> -	for_each_reserved_mem_range(i, &start, &end)</i><br>
><i> -		reserve_bootmem_region(start, end);</i><br>
><i> +	memmap_init_reserved_pages();</i><br>
><i>  </i><br>
><i>  	/*</i><br>
><i>  	 * We need to use NUMA_NO_NODE instead of NODE_DATA(0)->node_id</i><br>
><i> </i><br>
<br>
<br>

