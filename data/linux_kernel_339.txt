On Thu 08-04-21 10:31:55, Johannes Weiner wrote:<br>
><i> When the unsigned page_counter underflows, even just by a few pages, a</i><br>
><i> cgroup will not be able to run anything afterwards and trigger the OOM</i><br>
><i> killer in a loop.</i><br>
><i> </i><br>
><i> Underflows shouldn't happen, but when they do in practice, we may just</i><br>
><i> be off by a small amount that doesn't interfere with the normal</i><br>
><i> operation - consequences don't need to be that dire.</i><br>
<br>
Yes, I do agree.<br>
<br>
><i> Reset the page_counter to 0 upon underflow. We'll issue a warning that</i><br>
><i> the accounting will be off and then try to keep limping along.</i><br>
<br>
I do not remember any reports about the existing WARN_ON but it is not<br>
really hard to imagine a charging imbalance to be introduced easily.<br>
<br>
><i> [ We used to do this with the original res_counter, where it was a</i><br>
><i>   more straight-forward correction inside the spinlock section. I</i><br>
><i>   didn't carry it forward into the lockless page counters for</i><br>
><i>   simplicity, but it turns out this is quite useful in practice. ]</i><br>
<br>
The lack of external synchronization makes it more tricky because<br>
certain charges might get just lost depending on the ordering. This<br>
sucks but considering that the system is already botched and counters<br>
cannot be trusted this is definitely better than a potentially<br>
completely unusable memcg. It would be nice to mention that in the above<br>
paragraph as a caveat.<br>
<br>
><i> Signed-off-by: Johannes Weiner <hannes@xxxxxxxxxxx></i><br>
<br>
Acked-by: Michal Hocko <mhocko@xxxxxxxx><br>
<br>
><i> ---</i><br>
><i>  mm/page_counter.c | 8 ++++++--</i><br>
><i>  1 file changed, 6 insertions(+), 2 deletions(-)</i><br>
><i> </i><br>
><i> diff --git a/mm/page_counter.c b/mm/page_counter.c</i><br>
><i> index c6860f51b6c6..7d83641eb86b 100644</i><br>
><i> --- a/mm/page_counter.c</i><br>
><i> +++ b/mm/page_counter.c</i><br>
><i> @@ -52,9 +52,13 @@ void page_counter_cancel(struct page_counter *counter, unsigned long nr_pages)</i><br>
><i>  	long new;</i><br>
><i>  </i><br>
><i>  	new = atomic_long_sub_return(nr_pages, &counter->usage);</i><br>
><i> -	propagate_protected_usage(counter, new);</i><br>
><i>  	/* More uncharges than charges? */</i><br>
><i> -	WARN_ON_ONCE(new < 0);</i><br>
><i> +	if (WARN_ONCE(new < 0, "page_counter underflow: %ld nr_pages=%lu\n",</i><br>
><i> +		      new, nr_pages)) {</i><br>
><i> +		new = 0;</i><br>
><i> +		atomic_long_set(&counter->usage, new);</i><br>
><i> +	}</i><br>
><i> +	propagate_protected_usage(counter, new);</i><br>
><i>  }</i><br>
><i>  </i><br>
><i>  /**</i><br>
><i> -- </i><br>
><i> 2.31.1</i><br>
<br>
-- <br>
Michal Hocko<br>
SUSE Labs<br>
<br>
<br>

