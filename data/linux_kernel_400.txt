Make AFS use the new netfs read helpers to implement the VM read<br>
operations:<br>
<br>
 - afs_readpage() now hands off responsibility to netfs_readpage().<br>
<br>
 - afs_readpages() is gone and replaced with afs_readahead().<br>
<br>
 - afs_readahead() just hands off responsibility to netfs_readahead().<br>
<br>
These make use of the cache if a cookie is supplied, otherwise just call<br>
the ->issue_op() method a sufficient number of times to complete the entire<br>
request.<br>
<br>
Changes:<br>
v5:<br>
- Use proper wait function for PG_fscache in afs_page_mkwrite()[1].<br>
- Use killable wait for PG_writeback in afs_page_mkwrite()[1].<br>
<br>
v4:<br>
- Folded in error handling fixes to afs_req_issue_op().<br>
- Added flag to netfs_subreq_terminated() to indicate that the caller may<br>
  have been running async and stuff that might sleep needs punting to a<br>
  workqueue.<br>
<br>
Signed-off-by: David Howells <dhowells@xxxxxxxxxx><br>
cc: linux-afs@xxxxxxxxxxxxxxxxxxx<br>
cc: linux-cachefs@xxxxxxxxxx<br>
cc: linux-fsdevel@xxxxxxxxxxxxxxx<br>
Link: <a  rel="nofollow" href="https://lore.kernel.org/r/2499407.1616505440@xxxxxxxxxxxxxxxxxxxxxx">https://lore.kernel.org/r/2499407.1616505440@xxxxxxxxxxxxxxxxxxxxxx</a> [1]<br>
Link: <a  rel="nofollow" href="https://lore.kernel.org/r/160588542733.3465195.7526541422073350302.stgit@xxxxxxxxxxxxxxxxxxxxxx/">https://lore.kernel.org/r/160588542733.3465195.7526541422073350302.stgit@xxxxxxxxxxxxxxxxxxxxxx/</a> # rfc<br>
Link: <a  rel="nofollow" href="https://lore.kernel.org/r/161118158436.1232039.3884845981224091996.stgit@xxxxxxxxxxxxxxxxxxxxxx/">https://lore.kernel.org/r/161118158436.1232039.3884845981224091996.stgit@xxxxxxxxxxxxxxxxxxxxxx/</a> # rfc<br>
Link: <a  rel="nofollow" href="https://lore.kernel.org/r/161161053540.2537118.14904446369309535330.stgit@xxxxxxxxxxxxxxxxxxxxxx/">https://lore.kernel.org/r/161161053540.2537118.14904446369309535330.stgit@xxxxxxxxxxxxxxxxxxxxxx/</a> # v2<br>
Link: <a  rel="nofollow" href="https://lore.kernel.org/r/161340418739.1303470.5908092911600241280.stgit@xxxxxxxxxxxxxxxxxxxxxx/">https://lore.kernel.org/r/161340418739.1303470.5908092911600241280.stgit@xxxxxxxxxxxxxxxxxxxxxx/</a> # v3<br>
Link: <a  rel="nofollow" href="https://lore.kernel.org/r/161539561926.286939.5729036262354802339.stgit@xxxxxxxxxxxxxxxxxxxxxx/">https://lore.kernel.org/r/161539561926.286939.5729036262354802339.stgit@xxxxxxxxxxxxxxxxxxxxxx/</a> # v4<br>
Link: <a  rel="nofollow" href="https://lore.kernel.org/r/161653817977.2770958.17696456811587237197.stgit@xxxxxxxxxxxxxxxxxxxxxx/">https://lore.kernel.org/r/161653817977.2770958.17696456811587237197.stgit@xxxxxxxxxxxxxxxxxxxxxx/</a> # v5<br>
---<br>
<br>
 fs/afs/Kconfig    |    1 <br>
 fs/afs/file.c     |  327 +++++++++++++----------------------------------------<br>
 fs/afs/fsclient.c |    1 <br>
 fs/afs/internal.h |    3 <br>
 fs/afs/write.c    |    7 +<br>
 5 files changed, 88 insertions(+), 251 deletions(-)<br>
<br>
diff --git a/fs/afs/Kconfig b/fs/afs/Kconfig<br>
index 1ad211d72b3b..fc8ba9142f2f 100644<br>
--- a/fs/afs/Kconfig<br>
+++ b/fs/afs/Kconfig<br>
@@ -4,6 +4,7 @@ config AFS_FS<br>
 	depends on INET<br>
 	select AF_RXRPC<br>
 	select DNS_RESOLVER<br>
+	select NETFS_SUPPORT<br>
 	help<br>
 	  If you say Y here, you will get an experimental Andrew File System<br>
 	  driver. It currently only supports unsecured read-only AFS access.<br>
diff --git a/fs/afs/file.c b/fs/afs/file.c<br>
index 2db810467d3f..10c6eaaac2cc 100644<br>
--- a/fs/afs/file.c<br>
+++ b/fs/afs/file.c<br>
@@ -14,6 +14,7 @@<br>
 #include <linux/gfp.h><br>
 #include <linux/task_io_accounting_ops.h><br>
 #include <linux/mm.h><br>
+#include <linux/netfs.h><br>
 #include "internal.h"<br>
 <br>
 static int afs_file_mmap(struct file *file, struct vm_area_struct *vma);<br>
@@ -22,8 +23,7 @@ static void afs_invalidatepage(struct page *page, unsigned int offset,<br>
 			       unsigned int length);<br>
 static int afs_releasepage(struct page *page, gfp_t gfp_flags);<br>
 <br>
-static int afs_readpages(struct file *filp, struct address_space *mapping,<br>
-			 struct list_head *pages, unsigned nr_pages);<br>
+static void afs_readahead(struct readahead_control *ractl);<br>
 <br>
 const struct file_operations afs_file_operations = {<br>
 	.open		= afs_open,<br>
@@ -47,7 +47,7 @@ const struct inode_operations afs_file_inode_operations = {<br>
 <br>
 const struct address_space_operations afs_fs_aops = {<br>
 	.readpage	= afs_readpage,<br>
-	.readpages	= afs_readpages,<br>
+	.readahead	= afs_readahead,<br>
 	.set_page_dirty	= afs_set_page_dirty,<br>
 	.launder_page	= afs_launder_page,<br>
 	.releasepage	= afs_releasepage,<br>
@@ -184,61 +184,17 @@ int afs_release(struct inode *inode, struct file *file)<br>
 }<br>
 <br>
 /*<br>
- * Handle completion of a read operation.<br>
+ * Allocate a new read record.<br>
  */<br>
-static void afs_file_read_done(struct afs_read *req)<br>
+struct afs_read *afs_alloc_read(gfp_t gfp)<br>
 {<br>
-	struct afs_vnode *vnode = req->vnode;<br>
-	struct page *page;<br>
-	pgoff_t index = req->pos >> PAGE_SHIFT;<br>
-	pgoff_t last = index + req->nr_pages - 1;<br>
-<br>
-	XA_STATE(xas, &vnode->vfs_inode.i_mapping->i_pages, index);<br>
-<br>
-	if (iov_iter_count(req->iter) > 0) {<br>
-		/* The read was short - clear the excess buffer. */<br>
-		_debug("afterclear %zx %zx %llx/%llx",<br>
-		       req->iter->iov_offset,<br>
-		       iov_iter_count(req->iter),<br>
-		       req->actual_len, req->len);<br>
-		iov_iter_zero(iov_iter_count(req->iter), req->iter);<br>
-	}<br>
-<br>
-	rcu_read_lock();<br>
-	xas_for_each(&xas, page, last) {<br>
-		page_endio(page, false, 0);<br>
-		put_page(page);<br>
-	}<br>
-	rcu_read_unlock();<br>
-<br>
-	task_io_account_read(req->len);<br>
-	req->cleanup = NULL;<br>
-}<br>
-<br>
-/*<br>
- * Dispose of our locks and refs on the pages if the read failed.<br>
- */<br>
-static void afs_file_read_cleanup(struct afs_read *req)<br>
-{<br>
-	struct page *page;<br>
-	pgoff_t index = req->pos >> PAGE_SHIFT;<br>
-	pgoff_t last = index + req->nr_pages - 1;<br>
-<br>
-	if (req->iter) {<br>
-		XA_STATE(xas, &req->vnode->vfs_inode.i_mapping->i_pages, index);<br>
-<br>
-		_enter("%lu,%u,%zu", index, req->nr_pages, iov_iter_count(req->iter));<br>
+	struct afs_read *req;<br>
 <br>
-		rcu_read_lock();<br>
-		xas_for_each(&xas, page, last) {<br>
-			BUG_ON(xa_is_value(page));<br>
-			BUG_ON(PageCompound(page));<br>
+	req = kzalloc(sizeof(struct afs_read), gfp);<br>
+	if (req)<br>
+		refcount_set(&req->usage, 1);<br>
 <br>
-			page_endio(page, false, req->error);<br>
-			put_page(page);<br>
-		}<br>
-		rcu_read_unlock();<br>
-	}<br>
+	return req;<br>
 }<br>
 <br>
 /*<br>
@@ -257,14 +213,20 @@ void afs_put_read(struct afs_read *req)<br>
 static void afs_fetch_data_notify(struct afs_operation *op)<br>
 {<br>
 	struct afs_read *req = op->fetch.req;<br>
+	struct netfs_read_subrequest *subreq = req->subreq;<br>
 	int error = op->error;<br>
 <br>
 	if (error == -ECONNABORTED)<br>
 		error = afs_abort_to_error(op->ac.abort_code);<br>
 	req->error = error;<br>
 <br>
-	if (req->done)<br>
+	if (subreq) {<br>
+		__set_bit(NETFS_SREQ_CLEAR_TAIL, &subreq->flags);<br>
+		netfs_subreq_terminated(subreq, error ?: req->actual_len, false);<br>
+		req->subreq = NULL;<br>
+	} else if (req->done) {<br>
 		req->done(req);<br>
+	}<br>
 }<br>
 <br>
 static void afs_fetch_data_success(struct afs_operation *op)<br>
@@ -308,8 +270,11 @@ int afs_fetch_data(struct afs_vnode *vnode, struct afs_read *req)<br>
 	       key_serial(req->key));<br>
 <br>
 	op = afs_alloc_operation(req->key, vnode->volume);<br>
-	if (IS_ERR(op))<br>
+	if (IS_ERR(op)) {<br>
+		if (req->subreq)<br>
+			netfs_subreq_terminated(req->subreq, PTR_ERR(op), false);<br>
 		return PTR_ERR(op);<br>
+	}<br>
 <br>
 	afs_op_set_vnode(op, 0, vnode);<br>
 <br>
@@ -318,222 +283,86 @@ int afs_fetch_data(struct afs_vnode *vnode, struct afs_read *req)<br>
 	return afs_do_sync_operation(op);<br>
 }<br>
 <br>
-/*<br>
- * read page from file, directory or symlink, given a key to use<br>
- */<br>
-static int afs_page_filler(struct key *key, struct page *page)<br>
+static void afs_req_issue_op(struct netfs_read_subrequest *subreq)<br>
 {<br>
-	struct inode *inode = page->mapping->host;<br>
-	struct afs_vnode *vnode = AFS_FS_I(inode);<br>
-	struct afs_read *req;<br>
-	int ret;<br>
-<br>
-	_enter("{%x},{%lu},{%lu}", key_serial(key), inode->i_ino, page->index);<br>
+	struct afs_vnode *vnode = AFS_FS_I(subreq->rreq->inode);<br>
+	struct afs_read *fsreq;<br>
 <br>
-	BUG_ON(!PageLocked(page));<br>
-<br>
-	ret = -ESTALE;<br>
-	if (test_bit(AFS_VNODE_DELETED, &vnode->flags))<br>
-		goto error;<br>
+	fsreq = afs_alloc_read(GFP_NOFS);<br>
+	if (!fsreq)<br>
+		return netfs_subreq_terminated(subreq, -ENOMEM, false);<br>
 <br>
-	req = kzalloc(sizeof(struct afs_read), GFP_KERNEL);<br>
-	if (!req)<br>
-		goto enomem;<br>
-<br>
-	refcount_set(&req->usage, 1);<br>
-	req->vnode		= vnode;<br>
-	req->key		= key_get(key);<br>
-	req->pos		= (loff_t)page->index << PAGE_SHIFT;<br>
-	req->len		= thp_size(page);<br>
-	req->nr_pages		= thp_nr_pages(page);<br>
-	req->done		= afs_file_read_done;<br>
-	req->cleanup		= afs_file_read_cleanup;<br>
-<br>
-	get_page(page);<br>
-	iov_iter_xarray(&req->def_iter, READ, &page->mapping->i_pages,<br>
-			req->pos, req->len);<br>
-	req->iter = &req->def_iter;<br>
-<br>
-	ret = afs_fetch_data(vnode, req);<br>
-	if (ret < 0)<br>
-		goto fetch_error;<br>
+	fsreq->subreq	= subreq;<br>
+	fsreq->pos	= subreq->start + subreq->transferred;<br>
+	fsreq->len	= subreq->len   - subreq->transferred;<br>
+	fsreq->key	= subreq->rreq->netfs_priv;<br>
+	fsreq->vnode	= vnode;<br>
+	fsreq->iter	= &fsreq->def_iter;<br>
 <br>
-	afs_put_read(req);<br>
-	_leave(" = 0");<br>
-	return 0;<br>
+	iov_iter_xarray(&fsreq->def_iter, READ,<br>
+			&fsreq->vnode->vfs_inode.i_mapping->i_pages,<br>
+			fsreq->pos, fsreq->len);<br>
 <br>
-fetch_error:<br>
-	switch (ret) {<br>
-	case -EINTR:<br>
-	case -ENOMEM:<br>
-	case -ERESTARTSYS:<br>
-	case -EAGAIN:<br>
-		afs_put_read(req);<br>
-		goto error;<br>
-	case -ENOENT:<br>
-		_debug("got NOENT from server - marking file deleted and stale");<br>
-		set_bit(AFS_VNODE_DELETED, &vnode->flags);<br>
-		ret = -ESTALE;<br>
-		/* Fall through */<br>
-	default:<br>
-		page_endio(page, false, ret);<br>
-		afs_put_read(req);<br>
-		_leave(" = %d", ret);<br>
-		return ret;<br>
-	}<br>
-<br>
-enomem:<br>
-	ret = -ENOMEM;<br>
-error:<br>
-	unlock_page(page);<br>
-	_leave(" = %d", ret);<br>
-	return ret;<br>
+	afs_fetch_data(fsreq->vnode, fsreq);<br>
 }<br>
 <br>
-/*<br>
- * read page from file, directory or symlink, given a file to nominate the key<br>
- * to be used<br>
- */<br>
-static int afs_readpage(struct file *file, struct page *page)<br>
+static int afs_symlink_readpage(struct page *page)<br>
 {<br>
-	struct key *key;<br>
+	struct afs_vnode *vnode = AFS_FS_I(page->mapping->host);<br>
+	struct afs_read *fsreq;<br>
 	int ret;<br>
 <br>
-	if (file) {<br>
-		key = afs_file_key(file);<br>
-		ASSERT(key != NULL);<br>
-		ret = afs_page_filler(key, page);<br>
-	} else {<br>
-		struct inode *inode = page->mapping->host;<br>
-		key = afs_request_key(AFS_FS_S(inode->i_sb)->cell);<br>
-		if (IS_ERR(key)) {<br>
-			ret = PTR_ERR(key);<br>
-		} else {<br>
-			ret = afs_page_filler(key, page);<br>
-			key_put(key);<br>
-		}<br>
-	}<br>
-	return ret;<br>
-}<br>
-<br>
-/*<br>
- * Read a contiguous set of pages.<br>
- */<br>
-static int afs_readpages_one(struct file *file, struct address_space *mapping,<br>
-			     struct list_head *pages)<br>
-{<br>
-	struct afs_vnode *vnode = AFS_FS_I(mapping->host);<br>
-	struct afs_read *req;<br>
-	struct list_head *p;<br>
-	struct page *first, *page;<br>
-	pgoff_t index;<br>
-	int ret, n;<br>
-<br>
-	/* Count the number of contiguous pages at the front of the list.  Note<br>
-	 * that the list goes prev-wards rather than next-wards.<br>
-	 */<br>
-	first = lru_to_page(pages);<br>
-	index = first->index + 1;<br>
-	n = 1;<br>
-	for (p = first->lru.prev; p != pages; p = p->prev) {<br>
-		page = list_entry(p, struct page, lru);<br>
-		if (page->index != index)<br>
-			break;<br>
-		index++;<br>
-		n++;<br>
-	}<br>
-<br>
-	req = kzalloc(sizeof(struct afs_read), GFP_NOFS);<br>
-	if (!req)<br>
+	fsreq = afs_alloc_read(GFP_NOFS);<br>
+	if (!fsreq)<br>
 		return -ENOMEM;<br>
 <br>
-	refcount_set(&req->usage, 1);<br>
-	req->vnode = vnode;<br>
-	req->key = key_get(afs_file_key(file));<br>
-	req->done = afs_file_read_done;<br>
-	req->cleanup = afs_file_read_cleanup;<br>
-	req->pos = first->index;<br>
-	req->pos <<= PAGE_SHIFT;<br>
-<br>
-	/* Add pages to the LRU until it fails.  We keep the pages ref'd and<br>
-	 * locked until the read is complete.<br>
-	 *<br>
-	 * Note that it's possible for the file size to change whilst we're<br>
-	 * doing this, but we rely on the server returning less than we asked<br>
-	 * for if the file shrank.  We also rely on this to deal with a partial<br>
-	 * page at the end of the file.<br>
-	 */<br>
-	do {<br>
-		page = lru_to_page(pages);<br>
-		list_del(&page->lru);<br>
-		index = page->index;<br>
-		if (add_to_page_cache_lru(page, mapping, index,<br>
-					  readahead_gfp_mask(mapping))) {<br>
-			put_page(page);<br>
-			break;<br>
-		}<br>
-<br>
-		req->nr_pages++;<br>
-	} while (req->nr_pages < n);<br>
-<br>
-	if (req->nr_pages == 0) {<br>
-		afs_put_read(req);<br>
-		return 0;<br>
-	}<br>
-<br>
-	req->len = req->nr_pages * PAGE_SIZE;<br>
-	iov_iter_xarray(&req->def_iter, READ, &file->f_mapping->i_pages,<br>
-			req->pos, req->len);<br>
-	req->iter = &req->def_iter;<br>
+	fsreq->pos	= page->index * PAGE_SIZE;<br>
+	fsreq->len	= PAGE_SIZE;<br>
+	fsreq->vnode	= vnode;<br>
+	fsreq->iter	= &fsreq->def_iter;<br>
+	iov_iter_xarray(&fsreq->def_iter, READ, &page->mapping->i_pages,<br>
+			fsreq->pos, fsreq->len);<br>
 <br>
-	ret = afs_fetch_data(vnode, req);<br>
-	if (ret < 0)<br>
-		goto error;<br>
+	ret = afs_fetch_data(fsreq->vnode, fsreq);<br>
+	page_endio(page, false, ret);<br>
+	return ret;<br>
+}<br>
 <br>
-	afs_put_read(req);<br>
-	return 0;<br>
+static void afs_init_rreq(struct netfs_read_request *rreq, struct file *file)<br>
+{<br>
+	rreq->netfs_priv = key_get(afs_file_key(file));<br>
+}<br>
 <br>
-error:<br>
-	if (ret == -ENOENT) {<br>
-		_debug("got NOENT from server - marking file deleted and stale");<br>
-		set_bit(AFS_VNODE_DELETED, &vnode->flags);<br>
-		ret = -ESTALE;<br>
-	}<br>
+static int afs_begin_cache_operation(struct netfs_read_request *rreq)<br>
+{<br>
+	struct afs_vnode *vnode = AFS_FS_I(rreq->inode);<br>
 <br>
-	afs_put_read(req);<br>
-	return ret;<br>
+	return fscache_begin_read_operation(rreq, afs_vnode_cache(vnode));<br>
 }<br>
 <br>
-/*<br>
- * read a set of pages<br>
- */<br>
-static int afs_readpages(struct file *file, struct address_space *mapping,<br>
-			 struct list_head *pages, unsigned nr_pages)<br>
+static void afs_priv_cleanup(struct address_space *mapping, void *netfs_priv)<br>
 {<br>
-	struct key *key = afs_file_key(file);<br>
-	struct afs_vnode *vnode;<br>
-	int ret = 0;<br>
-<br>
-	_enter("{%d},{%lu},,%d",<br>
-	       key_serial(key), mapping->host->i_ino, nr_pages);<br>
+	key_put(netfs_priv);<br>
+}<br>
 <br>
-	ASSERT(key != NULL);<br>
+static const struct netfs_read_request_ops afs_req_ops = {<br>
+	.init_rreq		= afs_init_rreq,<br>
+	.begin_cache_operation	= afs_begin_cache_operation,<br>
+	.issue_op		= afs_req_issue_op,<br>
+	.cleanup		= afs_priv_cleanup,<br>
+};<br>
 <br>
-	vnode = AFS_FS_I(mapping->host);<br>
-	if (test_bit(AFS_VNODE_DELETED, &vnode->flags)) {<br>
-		_leave(" = -ESTALE");<br>
-		return -ESTALE;<br>
-	}<br>
+static int afs_readpage(struct file *file, struct page *page)<br>
+{<br>
+	if (!file)<br>
+		return afs_symlink_readpage(page);<br>
 <br>
-	/* attempt to read as many of the pages as possible */<br>
-	while (!list_empty(pages)) {<br>
-		ret = afs_readpages_one(file, mapping, pages);<br>
-		if (ret < 0)<br>
-			break;<br>
-	}<br>
+	return netfs_readpage(file, page, &afs_req_ops, NULL);<br>
+}<br>
 <br>
-	_leave(" = %d [netting]", ret);<br>
-	return ret;<br>
+static void afs_readahead(struct readahead_control *ractl)<br>
+{<br>
+	netfs_readahead(ractl, &afs_req_ops, NULL);<br>
 }<br>
 <br>
 /*<br>
diff --git a/fs/afs/fsclient.c b/fs/afs/fsclient.c<br>
index 5e34f4dbd385..2f695a260442 100644<br>
--- a/fs/afs/fsclient.c<br>
+++ b/fs/afs/fsclient.c<br>
@@ -10,6 +10,7 @@<br>
 #include <linux/sched.h><br>
 #include <linux/circ_buf.h><br>
 #include <linux/iversion.h><br>
+#include <linux/netfs.h><br>
 #include "internal.h"<br>
 #include "afs_fs.h"<br>
 #include "xdr_fs.h"<br>
diff --git a/fs/afs/internal.h b/fs/afs/internal.h<br>
index ee283e3ebc4d..f9a692fc08f4 100644<br>
--- a/fs/afs/internal.h<br>
+++ b/fs/afs/internal.h<br>
@@ -14,6 +14,7 @@<br>
 #include <linux/key.h><br>
 #include <linux/workqueue.h><br>
 #include <linux/sched.h><br>
+#define FSCACHE_USE_NEW_IO_API<br>
 #include <linux/fscache.h><br>
 #include <linux/backing-dev.h><br>
 #include <linux/uuid.h><br>
@@ -207,6 +208,7 @@ struct afs_read {<br>
 	loff_t			file_size;	/* File size returned by server */<br>
 	struct key		*key;		/* The key to use to reissue the read */<br>
 	struct afs_vnode	*vnode;		/* The file being read into. */<br>
+	struct netfs_read_subrequest *subreq;	/* Fscache helper read request this belongs to */<br>
 	afs_dataversion_t	data_version;	/* Version number returned by server */<br>
 	refcount_t		usage;<br>
 	unsigned int		call_debug_id;<br>
@@ -1049,6 +1051,7 @@ extern void afs_put_wb_key(struct afs_wb_key *);<br>
 extern int afs_open(struct inode *, struct file *);<br>
 extern int afs_release(struct inode *, struct file *);<br>
 extern int afs_fetch_data(struct afs_vnode *, struct afs_read *);<br>
+extern struct afs_read *afs_alloc_read(gfp_t);<br>
 extern void afs_put_read(struct afs_read *);<br>
 <br>
 static inline struct afs_read *afs_get_read(struct afs_read *req)<br>
diff --git a/fs/afs/write.c b/fs/afs/write.c<br>
index 099c7dad09c5..bc84c771b0fd 100644<br>
--- a/fs/afs/write.c<br>
+++ b/fs/afs/write.c<br>
@@ -930,7 +930,7 @@ vm_fault_t afs_page_mkwrite(struct vm_fault *vmf)<br>
 	 */<br>
 #ifdef CONFIG_AFS_FSCACHE<br>
 	if (PageFsCache(page) &&<br>
-	    wait_on_page_bit_killable(page, PG_fscache) < 0)<br>
+	    wait_on_page_fscache_killable(page) < 0)<br>
 		return VM_FAULT_RETRY;<br>
 #endif<br>
 <br>
@@ -944,7 +944,10 @@ vm_fault_t afs_page_mkwrite(struct vm_fault *vmf)<br>
 	 * details the portion of the page we need to write back and we might<br>
 	 * need to redirty the page if there's a problem.<br>
 	 */<br>
-	wait_on_page_writeback(page);<br>
+	if (wait_on_page_writeback_killable(page) < 0) {<br>
+		unlock_page(page);<br>
+		return VM_FAULT_RETRY;<br>
+	}<br>
 <br>
 	priv = afs_page_dirty(page, 0, thp_size(page));<br>
 	priv = afs_page_dirty_mmapped(priv);<br>
<br>
<br>
<br>

