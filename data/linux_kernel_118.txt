Some SoCs, such as the sd855 have OPPs within the same performance domain,<br>
whose cost is higher than others with a higher frequency. Even though<br>
those OPPs are interesting from a cooling perspective, it makes no sense<br>
to use them when the device can run at full capacity. Those OPPs handicap<br>
the performance domain, when choosing the most energy-efficient CPU and<br>
are wasting energy. They are inefficient.<br>
<br>
Hence, add support for such OPPs to the Energy Model, which creates for<br>
each OPP a performance state. The Energy Model can now be read using the<br>
regular table, which contains all performance states available, or using<br>
an efficient table, where inefficient performance states (and by<br>
extension, inefficient OPPs) have been removed.<br>
<br>
Currently, the efficient table is used in two paths. Schedutil, and<br>
find_energy_efficient_cpu(). We have to modify both paths in the same<br>
patch so they stay synchronized. The thermal framework still relies on<br>
the original table and hence, DevFreq devices won't create the efficient<br>
table.<br>
<br>
As used in the hot-path, the efficient table is a lookup table, generated<br>
dynamically when the perf domain is created. The complexity of searching<br>
a performance state is hence changed from O(n) to O(1). This also<br>
speeds-up em_cpu_energy() even if no inefficient OPPs have been found.<br>
<br>
Signed-off-by: Vincent Donnefort <vincent.donnefort@xxxxxxx><br>
<br>
diff --git a/include/linux/energy_model.h b/include/linux/energy_model.h<br>
index 757fc60..90b9cb0 100644<br>
--- a/include/linux/energy_model.h<br>
+++ b/include/linux/energy_model.h<br>
@@ -17,19 +17,60 @@<br>
  *		device). It can be a total power: static and dynamic.<br>
  * @cost:	The cost coefficient associated with this level, used during<br>
  *		energy calculation. Equal to: power * max_frequency / frequency<br>
+ * @flags:	see "em_perf_state flags" description below.<br>
  */<br>
 struct em_perf_state {<br>
 	unsigned long frequency;<br>
 	unsigned long power;<br>
 	unsigned long cost;<br>
+	unsigned long flags;<br>
+};<br>
+<br>
+/*<br>
+ * em_perf_state flags:<br>
+ *<br>
+ * EM_PERF_STATE_INEFFICIENT: The performance state is inefficient. There is<br>
+ * in this em_perf_domain, another performance state with a higher frequency<br>
+ * but a lower or equal power cost. Such inefficient states are ignored when<br>
+ * using em_pd_get_efficient_*() functions.<br>
+ */<br>
+#define EM_PERF_STATE_INEFFICIENT BIT(0)<br>
+<br>
+/**<br>
+ * em_efficient_table - Efficient em_perf_state lookup table.<br>
+ * @table:	Lookup table for the efficient em_perf_state<br>
+ * @min_state:  Minimum efficient state for the perf_domain<br>
+ * @max_state:  Maximum state for the perf_domain<br>
+ * @min_freq:	Minimum efficient frequency for the perf_domain<br>
+ * @max_freq:	Maximum frequency for the perf_domain<br>
+ * @shift:	Shift value used to resolve the lookup table<br>
+ *<br>
+ * Resolving a frequency to an efficient em_perf_state is as follows:<br>
+ *<br>
+ *   1. Check frequency against min_freq and max_freq<br>
+ *   2. idx = (frequency - min_freq) >> shift;<br>
+ *   3. idx = table[idx].frequency < frequency ? idx + 1 : idx;<br>
+ *   4. table[idx]<br>
+ *<br>
+ *   3. Intends to resolve undershoot, when an OPP is in the middle of the<br>
+ *   lookup table bin.<br>
+ */<br>
+struct em_efficient_table {<br>
+	struct em_perf_state **table;<br>
+	struct em_perf_state *min_state;<br>
+	struct em_perf_state *max_state;<br>
+	unsigned long min_freq;<br>
+	unsigned long max_freq;<br>
+	int shift;<br>
 };<br>
 <br>
 /**<br>
  * em_perf_domain - Performance domain<br>
  * @table:		List of performance states, in ascending order<br>
+ * @efficient_table:	List of efficient performance states, in a lookup<br>
+ *			table. This is filled only for CPU devices.<br>
  * @nr_perf_states:	Number of performance states<br>
- * @milliwatts:		Flag indicating the power values are in milli-Watts<br>
- *			or some other scale.<br>
+ * @flags:		See "em_perf_domain flags"<br>
  * @cpus:		Cpumask covering the CPUs of the domain. It's here<br>
  *			for performance reasons to avoid potential cache<br>
  *			misses during energy calculations in the scheduler<br>
@@ -43,11 +84,24 @@ struct em_perf_state {<br>
  */<br>
 struct em_perf_domain {<br>
 	struct em_perf_state *table;<br>
+	struct em_efficient_table efficient_table;<br>
 	int nr_perf_states;<br>
-	int milliwatts;<br>
+	int flags;<br>
 	unsigned long cpus[];<br>
 };<br>
 <br>
+/*<br>
+ *  em_perf_domain flags:<br>
+ *<br>
+ *  EM_PERF_DOMAIN_MILLIWATTS: The power values are in milli-Watts or some<br>
+ *  other scale.<br>
+ *<br>
+ *  EM_PERF_DOMAIN_INEFFICIENCIES: This perf domain contains inefficient perf<br>
+ *  states.<br>
+ */<br>
+#define EM_PERF_DOMAIN_MILLIWATTS BIT(0)<br>
+#define EM_PERF_DOMAIN_INEFFICIENCIES BIT(1)<br>
+<br>
 #define em_span_cpus(em) (to_cpumask((em)->cpus))<br>
 <br>
 #ifdef CONFIG_ENERGY_MODEL<br>
@@ -86,6 +140,63 @@ int em_dev_register_perf_domain(struct device *dev, unsigned int nr_states,<br>
 void em_dev_unregister_perf_domain(struct device *dev);<br>
 <br>
 /**<br>
+ * em_pd_get_efficient_state() - Get an efficient performance state from the EM<br>
+ * @pd   : Performance domain for which we want an efficient frequency<br>
+ * @freq : Frequency to map with the EM<br>
+ *<br>
+ * This function must be used only for CPU devices. It is called from the<br>
+ * scheduler code quite frequently and as a consequence doesn't implement any<br>
+ * check.<br>
+ *<br>
+ * Return: An efficient performance state, high enough to meet @freq<br>
+ * requirement.<br>
+ */<br>
+static inline<br>
+struct em_perf_state *em_pd_get_efficient_state(struct em_perf_domain *pd,<br>
+						unsigned long freq)<br>
+{<br>
+	struct em_efficient_table *efficients = &pd->efficient_table;<br>
+	int idx;<br>
+<br>
+	if (freq <= efficients->min_freq)<br>
+		return efficients->min_state;<br>
+<br>
+	if (freq >= efficients->max_freq)<br>
+		return efficients->max_state;<br>
+<br>
+	idx = (freq - efficients->min_freq) >> efficients->shift;<br>
+<br>
+	/* Undershoot due to the bin size. Use the higher perf_state */<br>
+	if (efficients->table[idx]->frequency < freq)<br>
+		idx++;<br>
+<br>
+	return efficients->table[idx];<br>
+}<br>
+<br>
+/**<br>
+ * em_pd_get_efficient_freq() - Get the efficient frequency from the EM<br>
+ * @pd	 : Performance domain for which we want an efficient frequency<br>
+ * @freq : Frequency to map with the EM<br>
+ *<br>
+ * This function will return @freq if no inefficiencies have been found for<br>
+ * that @pd. This is to avoid a useless lookup table resolution.<br>
+ *<br>
+ * Return: An efficient frequency, high enough to meet @freq requirement.<br>
+ */<br>
+static inline unsigned long em_pd_get_efficient_freq(struct em_perf_domain *pd,<br>
+						     unsigned long freq)<br>
+{<br>
+	struct em_perf_state *ps;<br>
+<br>
+	if (!pd || !(pd->flags & EM_PERF_DOMAIN_INEFFICIENCIES))<br>
+		return freq;<br>
+<br>
+	ps = em_pd_get_efficient_state(pd, freq);<br>
+<br>
+	return ps->frequency;<br>
+}<br>
+<br>
+/**<br>
  * em_cpu_energy() - Estimates the energy consumed by the CPUs of a<br>
 		performance domain<br>
  * @pd		: performance domain for which energy has to be estimated<br>
@@ -104,7 +215,7 @@ static inline unsigned long em_cpu_energy(struct em_perf_domain *pd,<br>
 {<br>
 	unsigned long freq, scale_cpu;<br>
 	struct em_perf_state *ps;<br>
-	int i, cpu;<br>
+	int cpu;<br>
 <br>
 	if (!sum_util)<br>
 		return 0;<br>
@@ -123,11 +234,7 @@ static inline unsigned long em_cpu_energy(struct em_perf_domain *pd,<br>
 	 * Find the lowest performance state of the Energy Model above the<br>
 	 * requested frequency.<br>
 	 */<br>
-	for (i = 0; i < pd->nr_perf_states; i++) {<br>
-		ps = &pd->table[i];<br>
-		if (ps->frequency >= freq)<br>
-			break;<br>
-	}<br>
+	ps = em_pd_get_efficient_state(pd, freq);<br>
 <br>
 	/*<br>
 	 * The capacity of a CPU in the domain at the performance state (ps)<br>
@@ -217,6 +324,12 @@ static inline int em_pd_nr_perf_states(struct em_perf_domain *pd)<br>
 {<br>
 	return 0;<br>
 }<br>
+<br>
+static inline unsigned long<br>
+em_pd_get_efficient_freq(struct em_perf_domain *pd, unsigned long freq)<br>
+{<br>
+	return freq;<br>
+}<br>
 #endif<br>
 <br>
 #endif<br>
diff --git a/kernel/power/energy_model.c b/kernel/power/energy_model.c<br>
index 1358fa4..fcc64eb 100644<br>
--- a/kernel/power/energy_model.c<br>
+++ b/kernel/power/energy_model.c<br>
@@ -2,7 +2,7 @@<br>
 /*<br>
  * Energy Model of devices<br>
  *<br>
- * Copyright (c) 2018-2020, Arm ltd.<br>
+ * Copyright (c) 2018-2021, Arm ltd.<br>
  * Written by: Quentin Perret, Arm ltd.<br>
  * Improvements provided by: Lukasz Luba, Arm ltd.<br>
  */<br>
@@ -42,6 +42,7 @@ static void em_debug_create_ps(struct em_perf_state *ps, struct dentry *pd)<br>
 	debugfs_create_ulong("frequency", 0444, d, &ps->frequency);<br>
 	debugfs_create_ulong("power", 0444, d, &ps->power);<br>
 	debugfs_create_ulong("cost", 0444, d, &ps->cost);<br>
+	debugfs_create_ulong("inefficient", 0444, d, &ps->flags);<br>
 }<br>
 <br>
 static int em_debug_cpus_show(struct seq_file *s, void *unused)<br>
@@ -55,7 +56,8 @@ DEFINE_SHOW_ATTRIBUTE(em_debug_cpus);<br>
 static int em_debug_units_show(struct seq_file *s, void *unused)<br>
 {<br>
 	struct em_perf_domain *pd = s->private;<br>
-	char *units = pd->milliwatts ? "milliWatts" : "bogoWatts";<br>
+	char *units = (pd->flags & EM_PERF_DOMAIN_MILLIWATTS) ?<br>
+		"milliWatts" : "bogoWatts";<br>
 <br>
 	seq_printf(s, "%s\n", units);<br>
 <br>
@@ -107,7 +109,6 @@ static void em_debug_remove_pd(struct device *dev) {}<br>
 static int em_create_perf_table(struct device *dev, struct em_perf_domain *pd,<br>
 				int nr_states, struct em_data_callback *cb)<br>
 {<br>
-	unsigned long opp_eff, prev_opp_eff = ULONG_MAX;<br>
 	unsigned long power, freq, prev_freq = 0;<br>
 	struct em_perf_state *table;<br>
 	int i, ret;<br>
@@ -153,18 +154,6 @@ static int em_create_perf_table(struct device *dev, struct em_perf_domain *pd,<br>
 <br>
 		table[i].power = power;<br>
 		table[i].frequency = prev_freq = freq;<br>
-<br>
-		/*<br>
-		 * The hertz/watts efficiency ratio should decrease as the<br>
-		 * frequency grows on sane platforms. But this isn't always<br>
-		 * true in practice so warn the user if a higher OPP is more<br>
-		 * power efficient than a lower one.<br>
-		 */<br>
-		opp_eff = freq / power;<br>
-		if (opp_eff >= prev_opp_eff)<br>
-			dev_dbg(dev, "EM: hertz/watts ratio non-monotonically decreasing: em_perf_state %d >= em_perf_state%d\n",<br>
-					i, i - 1);<br>
-		prev_opp_eff = opp_eff;<br>
 	}<br>
 <br>
 	/* Compute the cost of each performance state. */<br>
@@ -184,12 +173,88 @@ static int em_create_perf_table(struct device *dev, struct em_perf_domain *pd,<br>
 	return -EINVAL;<br>
 }<br>
 <br>
+static inline int em_create_efficient_table(struct em_perf_domain *pd)<br>
+{<br>
+	unsigned long min_freq, max_freq, min_delta = ULONG_MAX;<br>
+	struct em_perf_state *prev = NULL, *ps, *min_perf_state = NULL;<br>
+	int i, j, nr_entries, shift = 0;<br>
+<br>
+	max_freq = pd->table[pd->nr_perf_states - 1].frequency;<br>
+<br>
+	for (i = 0 ; i < pd->nr_perf_states; i++) {<br>
+		ps  = &pd->table[i];<br>
+		if (ps->flags & EM_PERF_STATE_INEFFICIENT)<br>
+			continue;<br>
+<br>
+		if (!min_perf_state)<br>
+			min_perf_state = ps;<br>
+<br>
+		if (prev) {<br>
+			unsigned long delta = ps->frequency - prev->frequency;<br>
+<br>
+			if (delta < min_delta)<br>
+				min_delta = delta;<br>
+		}<br>
+<br>
+		prev = ps;<br>
+	}<br>
+	min_freq = min_perf_state->frequency;<br>
+<br>
+	/*<br>
+	 * Use, as a bin size, a power of two. This allows lookup table<br>
+	 * resolution with a quick shift, instead of a division. Also, use a<br>
+	 * minimum of 1024kHz to avoid creating to many entries in the table for<br>
+	 * the very unlikely case where two efficient OPPs have a small<br>
+	 * frequency delta.<br>
+	 */<br>
+	min_delta = rounddown_pow_of_two(max(min_delta, 1024UL));<br>
+	shift = ilog2(min_delta);<br>
+	/* +1 for the division remainder below */<br>
+	nr_entries = ((max_freq - min_freq) >> shift) + 1;<br>
+<br>
+	pd->efficient_table.table = kcalloc(nr_entries,<br>
+					sizeof(*pd->efficient_table.table),<br>
+					GFP_KERNEL);<br>
+	if (!pd->efficient_table.table)<br>
+		return -ENOMEM;<br>
+<br>
+	pd->efficient_table.min_freq = min_freq;<br>
+	pd->efficient_table.min_state = min_perf_state;<br>
+	pd->efficient_table.max_freq = max_freq;<br>
+	pd->efficient_table.max_state = &pd->table[pd->nr_perf_states - 1];<br>
+	pd->efficient_table.shift = shift;<br>
+<br>
+	for (i = 0; i < nr_entries; i++) {<br>
+		unsigned long lower_bin_bound = min_freq + ((1 << shift) * i);<br>
+<br>
+		for (j = 0; j < pd->nr_perf_states; j++) {<br>
+			ps = &pd->table[j];<br>
+<br>
+			/*<br>
+			 * The first OPP that covers the lower bound of the bin<br>
+			 * is the right one. It ensures we'll never overshoot.<br>
+			 * Undershoot must be handled during the lookup table<br>
+			 * resolution.<br>
+			 */<br>
+			if (ps->flags & EM_PERF_STATE_INEFFICIENT ||<br>
+			    ps->frequency < lower_bin_bound)<br>
+				continue;<br>
+<br>
+			pd->efficient_table.table[i] = ps;<br>
+			break;<br>
+		}<br>
+	}<br>
+<br>
+	return 0;<br>
+}<br>
+<br>
 static int em_create_pd(struct device *dev, int nr_states,<br>
 			struct em_data_callback *cb, cpumask_t *cpus)<br>
 {<br>
 	struct em_perf_domain *pd;<br>
 	struct device *cpu_dev;<br>
-	int cpu, ret;<br>
+	unsigned int prev_cost;<br>
+	int cpu, ret, i;<br>
 <br>
 	if (_is_cpu_device(dev)) {<br>
 		pd = kzalloc(sizeof(*pd) + cpumask_size(), GFP_KERNEL);<br>
@@ -209,11 +274,35 @@ static int em_create_pd(struct device *dev, int nr_states,<br>
 		return ret;<br>
 	}<br>
 <br>
-	if (_is_cpu_device(dev))<br>
+	if (_is_cpu_device(dev)) {<br>
+		/* Identify inefficient perf states */<br>
+		i = pd->nr_perf_states - 1;<br>
+		prev_cost = pd->table[i].cost;<br>
+		for (--i; i >= 0; i--) {<br>
+			if (pd->table[i].cost >= prev_cost) {<br>
+				pd->table[i].flags = EM_PERF_STATE_INEFFICIENT;<br>
+				pd->flags |= EM_PERF_DOMAIN_INEFFICIENCIES;<br>
+				dev_dbg(dev,<br>
+					"EM: pd%d OPP:%lu is inefficient\n",<br>
+					cpumask_first(to_cpumask(pd->cpus)),<br>
+					pd->table[i].frequency);<br>
+				continue;<br>
+			}<br>
+			prev_cost = pd->table[i].cost;<br>
+		}<br>
+<br>
+		ret = em_create_efficient_table(pd);<br>
+		if (ret) {<br>
+			kfree(pd->table);<br>
+			kfree(pd);<br>
+			return ret;<br>
+		}<br>
+<br>
 		for_each_cpu(cpu, cpus) {<br>
 			cpu_dev = get_cpu_device(cpu);<br>
 			cpu_dev->em_pd = pd;<br>
 		}<br>
+	}<br>
 <br>
 	dev->em_pd = pd;<br>
 <br>
@@ -333,7 +422,8 @@ int em_dev_register_perf_domain(struct device *dev, unsigned int nr_states,<br>
 	if (ret)<br>
 		goto unlock;<br>
 <br>
-	dev->em_pd->milliwatts = milliwatts;<br>
+	if (milliwatts)<br>
+		dev->em_pd->flags |= EM_PERF_DOMAIN_MILLIWATTS;<br>
 <br>
 	em_debug_create_pd(dev);<br>
 	dev_info(dev, "EM: created perf domain\n");<br>
diff --git a/kernel/sched/cpufreq_schedutil.c b/kernel/sched/cpufreq_schedutil.c<br>
index 7cc2e11..3eefd4c 100644<br>
--- a/kernel/sched/cpufreq_schedutil.c<br>
+++ b/kernel/sched/cpufreq_schedutil.c<br>
@@ -10,6 +10,7 @@<br>
 <br>
 #include "sched.h"<br>
 <br>
+#include <linux/energy_model.h><br>
 #include <linux/sched/cpufreq.h><br>
 #include <trace/events/power.h><br>
 <br>
@@ -164,6 +165,9 @@ static unsigned int get_next_freq(struct sugov_policy *sg_policy,<br>
 <br>
 	freq = map_util_freq(util, freq, max);<br>
 <br>
+	/* Avoid inefficient performance states */<br>
+	freq = em_pd_get_efficient_freq(em_cpu_get(policy->cpu), freq);<br>
+<br>
 	if (freq == sg_policy->cached_raw_freq && !sg_policy->need_freq_update)<br>
 		return sg_policy->next_freq;<br>
 <br>
-- <br>
2.7.4<br>
<br>
<br>

